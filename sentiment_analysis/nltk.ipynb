{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=X2vAabgKiuM&t=871s\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc',\n",
       " 'abc.zip',\n",
       " 'alpino',\n",
       " 'alpino.zip',\n",
       " 'biocreative_ppi',\n",
       " 'biocreative_ppi.zip',\n",
       " 'brown',\n",
       " 'brown.zip',\n",
       " 'brown_tei',\n",
       " 'brown_tei.zip',\n",
       " 'cess_cat',\n",
       " 'cess_cat.zip',\n",
       " 'cess_esp',\n",
       " 'cess_esp.zip',\n",
       " 'chat80',\n",
       " 'chat80.zip',\n",
       " 'city_database',\n",
       " 'city_database.zip',\n",
       " 'cmudict',\n",
       " 'cmudict.zip',\n",
       " 'comparative_sentences',\n",
       " 'comparative_sentences.zip',\n",
       " 'comtrans.zip',\n",
       " 'conll2000',\n",
       " 'conll2000.zip',\n",
       " 'conll2002',\n",
       " 'conll2002.zip',\n",
       " 'conll2007.zip',\n",
       " 'crubadan',\n",
       " 'crubadan.zip',\n",
       " 'dependency_treebank',\n",
       " 'dependency_treebank.zip',\n",
       " 'dolch',\n",
       " 'dolch.zip',\n",
       " 'europarl_raw',\n",
       " 'europarl_raw.zip',\n",
       " 'floresta',\n",
       " 'floresta.zip',\n",
       " 'framenet_v15',\n",
       " 'framenet_v15.zip',\n",
       " 'framenet_v17',\n",
       " 'framenet_v17.zip',\n",
       " 'gazetteers',\n",
       " 'gazetteers.zip',\n",
       " 'genesis',\n",
       " 'genesis.zip',\n",
       " 'gutenberg',\n",
       " 'gutenberg.zip',\n",
       " 'ieer',\n",
       " 'ieer.zip',\n",
       " 'inaugural',\n",
       " 'inaugural.zip',\n",
       " 'indian',\n",
       " 'indian.zip',\n",
       " 'jeita.zip',\n",
       " 'kimmo',\n",
       " 'kimmo.zip',\n",
       " 'knbc.zip',\n",
       " 'lin_thesaurus',\n",
       " 'lin_thesaurus.zip',\n",
       " 'machado.zip',\n",
       " 'mac_morpho',\n",
       " 'mac_morpho.zip',\n",
       " 'masc_tagged.zip',\n",
       " 'movie_reviews',\n",
       " 'movie_reviews.zip',\n",
       " 'mte_teip5',\n",
       " 'mte_teip5.zip',\n",
       " 'names',\n",
       " 'names.zip',\n",
       " 'nombank.1.0.zip',\n",
       " 'nonbreaking_prefixes',\n",
       " 'nonbreaking_prefixes.zip',\n",
       " 'nps_chat',\n",
       " 'nps_chat.zip',\n",
       " 'omw',\n",
       " 'omw.zip',\n",
       " 'opinion_lexicon',\n",
       " 'opinion_lexicon.zip',\n",
       " 'panlex_swadesh.zip',\n",
       " 'paradigms',\n",
       " 'paradigms.zip',\n",
       " 'pil',\n",
       " 'pil.zip',\n",
       " 'pl196x',\n",
       " 'pl196x.zip',\n",
       " 'ppattach',\n",
       " 'ppattach.zip',\n",
       " 'problem_reports',\n",
       " 'problem_reports.zip',\n",
       " 'product_reviews_1',\n",
       " 'product_reviews_1.zip',\n",
       " 'product_reviews_2',\n",
       " 'product_reviews_2.zip',\n",
       " 'propbank.zip',\n",
       " 'pros_cons',\n",
       " 'pros_cons.zip',\n",
       " 'ptb',\n",
       " 'ptb.zip',\n",
       " 'qc',\n",
       " 'qc.zip',\n",
       " 'reuters.zip',\n",
       " 'rte',\n",
       " 'rte.zip',\n",
       " 'semcor.zip',\n",
       " 'senseval',\n",
       " 'senseval.zip',\n",
       " 'sentence_polarity',\n",
       " 'sentence_polarity.zip',\n",
       " 'sentiwordnet',\n",
       " 'sentiwordnet.zip',\n",
       " 'shakespeare',\n",
       " 'shakespeare.zip',\n",
       " 'sinica_treebank',\n",
       " 'sinica_treebank.zip',\n",
       " 'smultron',\n",
       " 'smultron.zip',\n",
       " 'state_union',\n",
       " 'state_union.zip',\n",
       " 'stopwords',\n",
       " 'stopwords.zip',\n",
       " 'subjectivity',\n",
       " 'subjectivity.zip',\n",
       " 'swadesh',\n",
       " 'swadesh.zip',\n",
       " 'switchboard',\n",
       " 'switchboard.zip',\n",
       " 'timit',\n",
       " 'timit.zip',\n",
       " 'toolbox',\n",
       " 'toolbox.zip',\n",
       " 'treebank',\n",
       " 'treebank.zip',\n",
       " 'twitter_samples',\n",
       " 'twitter_samples.zip',\n",
       " 'udhr',\n",
       " 'udhr.zip',\n",
       " 'udhr2',\n",
       " 'udhr2.zip',\n",
       " 'unicode_samples',\n",
       " 'unicode_samples.zip',\n",
       " 'universal_treebanks_v20.zip',\n",
       " 'verbnet',\n",
       " 'verbnet.zip',\n",
       " 'webtext',\n",
       " 'webtext.zip',\n",
       " 'wordnet',\n",
       " 'wordnet.zip',\n",
       " 'wordnet_ic',\n",
       " 'wordnet_ic.zip',\n",
       " 'words',\n",
       " 'words.zip',\n",
       " 'ycoe',\n",
       " 'ycoe.zip']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(nltk.data.find('corpora'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had "
     ]
    }
   ],
   "source": [
    "for word in hamlet[:100]:\n",
    "    print(word, sep=\" \", end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI = \"\"\"John McCarthy, an American computer scientist pioneer and inventor, was known as the father of Artificial Intelligence (AI) after playing a seminal role in defining the field devoted to the development of intelligent machines. The cognitive scientist coined the term in his 1955 proposal for the 1956 Dartmouth Conference, the first artificial intelligence conference. The objective was to explore ways to make a machine that could reason like a human, was capable of abstract thought, problem-solving and self-improvement. He believed that \"every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\"\n",
    "\"\"\"\n",
    "\n",
    "type(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'McCarthy',\n",
       " ',',\n",
       " 'an',\n",
       " 'American',\n",
       " 'computer',\n",
       " 'scientist',\n",
       " 'pioneer',\n",
       " 'and',\n",
       " 'inventor',\n",
       " ',',\n",
       " 'was',\n",
       " 'known',\n",
       " 'as',\n",
       " 'the',\n",
       " 'father',\n",
       " 'of',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '(',\n",
       " 'AI',\n",
       " ')',\n",
       " 'after',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'seminal',\n",
       " 'role',\n",
       " 'in',\n",
       " 'defining',\n",
       " 'the',\n",
       " 'field',\n",
       " 'devoted',\n",
       " 'to',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'intelligent',\n",
       " 'machines',\n",
       " '.',\n",
       " 'The',\n",
       " 'cognitive',\n",
       " 'scientist',\n",
       " 'coined',\n",
       " 'the',\n",
       " 'term',\n",
       " 'in',\n",
       " 'his',\n",
       " '1955',\n",
       " 'proposal',\n",
       " 'for',\n",
       " 'the',\n",
       " '1956',\n",
       " 'Dartmouth',\n",
       " 'Conference',\n",
       " ',',\n",
       " 'the',\n",
       " 'first',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'conference',\n",
       " '.',\n",
       " 'The',\n",
       " 'objective',\n",
       " 'was',\n",
       " 'to',\n",
       " 'explore',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'that',\n",
       " 'could',\n",
       " 'reason',\n",
       " 'like',\n",
       " 'a',\n",
       " 'human',\n",
       " ',',\n",
       " 'was',\n",
       " 'capable',\n",
       " 'of',\n",
       " 'abstract',\n",
       " 'thought',\n",
       " ',',\n",
       " 'problem-solving',\n",
       " 'and',\n",
       " 'self-improvement',\n",
       " '.',\n",
       " 'He',\n",
       " 'believed',\n",
       " 'that',\n",
       " '``',\n",
       " 'every',\n",
       " 'aspect',\n",
       " 'of',\n",
       " 'learning',\n",
       " 'or',\n",
       " 'any',\n",
       " 'other',\n",
       " 'feature',\n",
       " 'of',\n",
       " 'intelligence',\n",
       " 'can',\n",
       " 'in',\n",
       " 'principle',\n",
       " 'be',\n",
       " 'so',\n",
       " 'precisely',\n",
       " 'described',\n",
       " 'that',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'can',\n",
       " 'be',\n",
       " 'made',\n",
       " 'to',\n",
       " 'simulate',\n",
       " 'it',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_tokens = word_tokenize(AI)\n",
    "AI_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({\"''\": 1,\n",
       "          '(': 1,\n",
       "          ')': 1,\n",
       "          ',': 5,\n",
       "          '.': 4,\n",
       "          '1955': 1,\n",
       "          '1956': 1,\n",
       "          '``': 1,\n",
       "          'a': 4,\n",
       "          'abstract': 1,\n",
       "          'after': 1,\n",
       "          'ai': 1,\n",
       "          'american': 1,\n",
       "          'an': 1,\n",
       "          'and': 2,\n",
       "          'any': 1,\n",
       "          'artificial': 2,\n",
       "          'as': 1,\n",
       "          'aspect': 1,\n",
       "          'be': 2,\n",
       "          'believed': 1,\n",
       "          'can': 2,\n",
       "          'capable': 1,\n",
       "          'cognitive': 1,\n",
       "          'coined': 1,\n",
       "          'computer': 1,\n",
       "          'conference': 2,\n",
       "          'could': 1,\n",
       "          'dartmouth': 1,\n",
       "          'defining': 1,\n",
       "          'described': 1,\n",
       "          'development': 1,\n",
       "          'devoted': 1,\n",
       "          'every': 1,\n",
       "          'explore': 1,\n",
       "          'father': 1,\n",
       "          'feature': 1,\n",
       "          'field': 1,\n",
       "          'first': 1,\n",
       "          'for': 1,\n",
       "          'he': 1,\n",
       "          'his': 1,\n",
       "          'human': 1,\n",
       "          'in': 3,\n",
       "          'intelligence': 3,\n",
       "          'intelligent': 1,\n",
       "          'inventor': 1,\n",
       "          'it': 1,\n",
       "          'john': 1,\n",
       "          'known': 1,\n",
       "          'learning': 1,\n",
       "          'like': 1,\n",
       "          'machine': 2,\n",
       "          'machines': 1,\n",
       "          'made': 1,\n",
       "          'make': 1,\n",
       "          'mccarthy': 1,\n",
       "          'objective': 1,\n",
       "          'of': 5,\n",
       "          'or': 1,\n",
       "          'other': 1,\n",
       "          'pioneer': 1,\n",
       "          'playing': 1,\n",
       "          'precisely': 1,\n",
       "          'principle': 1,\n",
       "          'problem-solving': 1,\n",
       "          'proposal': 1,\n",
       "          'reason': 1,\n",
       "          'role': 1,\n",
       "          'scientist': 2,\n",
       "          'self-improvement': 1,\n",
       "          'seminal': 1,\n",
       "          'simulate': 1,\n",
       "          'so': 1,\n",
       "          'term': 1,\n",
       "          'that': 3,\n",
       "          'the': 8,\n",
       "          'thought': 1,\n",
       "          'to': 4,\n",
       "          'was': 3,\n",
       "          'ways': 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in AI_tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['artificial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 8),\n",
       " (',', 5),\n",
       " ('of', 5),\n",
       " ('a', 4),\n",
       " ('to', 4),\n",
       " ('.', 4),\n",
       " ('was', 3),\n",
       " ('intelligence', 3),\n",
       " ('in', 3),\n",
       " ('that', 3)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10 = fdist.most_common(10)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  nltk.tokenize import blankline_tokenize\n",
    "AI_blank = blankline_tokenize(AI)\n",
    "len(AI_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John McCarthy, an American computer scientist pioneer and inventor, was known as the father of Artificial Intelligence (AI) after playing a seminal role in defining the field devoted to the development of intelligent machines. The cognitive scientist coined the term in his 1955 proposal for the 1956 Dartmouth Conference, the first artificial intelligence conference. The objective was to explore ways to make a machine that could reason like a human, was capable of abstract thought, problem-solving and self-improvement. He believed that \"every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\"\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_blank[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'best',\n",
       " 'and',\n",
       " 'most',\n",
       " 'beautiful',\n",
       " 'tings',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'can',\n",
       " 'not',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'or',\n",
       " 'even',\n",
       " 'touched',\n",
       " ',',\n",
       " 'they',\n",
       " 'must',\n",
       " 'be',\n",
       " 'felt',\n",
       " 'with',\n",
       " 'the',\n",
       " 'heart']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'The best and most beautiful tings in the world cannot be seen or even touched, they must be felt with the heart'\n",
    "quotes_tokens = nltk.word_tokenize(string)\n",
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'best'),\n",
       " ('best', 'and'),\n",
       " ('and', 'most'),\n",
       " ('most', 'beautiful'),\n",
       " ('beautiful', 'tings'),\n",
       " ('tings', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'world'),\n",
       " ('world', 'can'),\n",
       " ('can', 'not'),\n",
       " ('not', 'be'),\n",
       " ('be', 'seen'),\n",
       " ('seen', 'or'),\n",
       " ('or', 'even'),\n",
       " ('even', 'touched'),\n",
       " ('touched', ','),\n",
       " (',', 'they'),\n",
       " ('they', 'must'),\n",
       " ('must', 'be'),\n",
       " ('be', 'felt'),\n",
       " ('felt', 'with'),\n",
       " ('with', 'the'),\n",
       " ('the', 'heart')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_bigrams = list(nltk.bigrams(quotes_tokens))\n",
    "quotes_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'best', 'and'),\n",
       " ('best', 'and', 'most'),\n",
       " ('and', 'most', 'beautiful'),\n",
       " ('most', 'beautiful', 'tings'),\n",
       " ('beautiful', 'tings', 'in'),\n",
       " ('tings', 'in', 'the'),\n",
       " ('in', 'the', 'world'),\n",
       " ('the', 'world', 'can'),\n",
       " ('world', 'can', 'not'),\n",
       " ('can', 'not', 'be'),\n",
       " ('not', 'be', 'seen'),\n",
       " ('be', 'seen', 'or'),\n",
       " ('seen', 'or', 'even'),\n",
       " ('or', 'even', 'touched'),\n",
       " ('even', 'touched', ','),\n",
       " ('touched', ',', 'they'),\n",
       " (',', 'they', 'must'),\n",
       " ('they', 'must', 'be'),\n",
       " ('must', 'be', 'felt'),\n",
       " ('be', 'felt', 'with'),\n",
       " ('felt', 'with', 'the'),\n",
       " ('with', 'the', 'heart')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_trigrams = list(nltk.trigrams(quotes_tokens))\n",
    "quotes_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'best', 'and', 'most', 'beautiful'),\n",
       " ('best', 'and', 'most', 'beautiful', 'tings'),\n",
       " ('and', 'most', 'beautiful', 'tings', 'in'),\n",
       " ('most', 'beautiful', 'tings', 'in', 'the'),\n",
       " ('beautiful', 'tings', 'in', 'the', 'world'),\n",
       " ('tings', 'in', 'the', 'world', 'can'),\n",
       " ('in', 'the', 'world', 'can', 'not'),\n",
       " ('the', 'world', 'can', 'not', 'be'),\n",
       " ('world', 'can', 'not', 'be', 'seen'),\n",
       " ('can', 'not', 'be', 'seen', 'or'),\n",
       " ('not', 'be', 'seen', 'or', 'even'),\n",
       " ('be', 'seen', 'or', 'even', 'touched'),\n",
       " ('seen', 'or', 'even', 'touched', ','),\n",
       " ('or', 'even', 'touched', ',', 'they'),\n",
       " ('even', 'touched', ',', 'they', 'must'),\n",
       " ('touched', ',', 'they', 'must', 'be'),\n",
       " (',', 'they', 'must', 'be', 'felt'),\n",
       " ('they', 'must', 'be', 'felt', 'with'),\n",
       " ('must', 'be', 'felt', 'with', 'the'),\n",
       " ('be', 'felt', 'with', 'the', 'heart')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_ngrams = list(nltk.ngrams(quotes_tokens, 5))\n",
    "quotes_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming normalize words into its base form or root form\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "pst.stem('having')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = ['give', 'giving', 'given', 'gave']\n",
    "for words in words_to_stem:\n",
    "    print(words + \":\" + pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:giv\n",
      "giving:giv\n",
      "given:giv\n",
      "gave:gav\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "for words in words_to_stem:\n",
    "    print(words + \":\" + lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "sbst = SnowballStemmer('english')\n",
    "for words in words_to_stem:\n",
    "    print(words + \":\" + sbst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:giving\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words + \":\" + word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation = re.compile(r'[-.?!,:;()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_punctuation = []\n",
    "for words in AI_tokens:\n",
    "    word = punctuation.sub('',words)\n",
    "    if len(word) > 0:\n",
    "        post_punctuation.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'McCarthy',\n",
       " 'an',\n",
       " 'American',\n",
       " 'computer',\n",
       " 'scientist',\n",
       " 'pioneer',\n",
       " 'and',\n",
       " 'inventor',\n",
       " 'was',\n",
       " 'known',\n",
       " 'as',\n",
       " 'the',\n",
       " 'father',\n",
       " 'of',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'AI',\n",
       " 'after',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'seminal',\n",
       " 'role',\n",
       " 'in',\n",
       " 'defining',\n",
       " 'the',\n",
       " 'field',\n",
       " 'devoted',\n",
       " 'to',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'intelligent',\n",
       " 'machines',\n",
       " 'The',\n",
       " 'cognitive',\n",
       " 'scientist',\n",
       " 'coined',\n",
       " 'the',\n",
       " 'term',\n",
       " 'in',\n",
       " 'his',\n",
       " 'proposal',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Dartmouth',\n",
       " 'Conference',\n",
       " 'the',\n",
       " 'first',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'conference',\n",
       " 'The',\n",
       " 'objective',\n",
       " 'was',\n",
       " 'to',\n",
       " 'explore',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'that',\n",
       " 'could',\n",
       " 'reason',\n",
       " 'like',\n",
       " 'a',\n",
       " 'human',\n",
       " 'was',\n",
       " 'capable',\n",
       " 'of',\n",
       " 'abstract',\n",
       " 'thought',\n",
       " 'problemsolving',\n",
       " 'and',\n",
       " 'selfimprovement',\n",
       " 'He',\n",
       " 'believed',\n",
       " 'that',\n",
       " '``',\n",
       " 'every',\n",
       " 'aspect',\n",
       " 'of',\n",
       " 'learning',\n",
       " 'or',\n",
       " 'any',\n",
       " 'other',\n",
       " 'feature',\n",
       " 'of',\n",
       " 'intelligence',\n",
       " 'can',\n",
       " 'in',\n",
       " 'principle',\n",
       " 'be',\n",
       " 'so',\n",
       " 'precisely',\n",
       " 'described',\n",
       " 'that',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'can',\n",
       " 'be',\n",
       " 'made',\n",
       " 'to',\n",
       " 'simulate',\n",
       " 'it',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = 'Timothy is a natural when it comes to drawing'\n",
    "sent_tokens = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Timothy', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('drawing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
